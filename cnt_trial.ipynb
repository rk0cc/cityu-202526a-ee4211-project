{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cars and tanks trial run",
   "id": "40ac5e76554f6448"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Preference variables\n",
    "LAST_TRAIN_MODE=False"
   ],
   "id": "f91fd249e0642870"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "model_file = \"yolo11_cnt_last.pt\" if LAST_TRAIN_MODE else \"yolo11_cnt_best.pt\"\n",
    "\n",
    "if not os.path.exists(model_file):\n",
    "    dl_link = {\n",
    "        \"yolo11_cnt_best.pt\": \"https://drive.google.com/uc?export=download&id=1zfCXSVrKpa38N9EauT-Z18xXgFPl6kuI\",\n",
    "        \"yolo11_cnt_last.pt\": \"https://drive.google.com/uc?export=download&id=1_gkYs4yPl8kTgON-uJBKfsX3bAP5cf42\"\n",
    "    }\n",
    "\n",
    "    with requests.get(dl_link[model_file], stream=True) as response:\n",
    "        response.raise_for_status()\n",
    "        with open(model_file, \"wb\") as f:\n",
    "            for c in response.iter_content(chunk_size=1024 * 256):\n",
    "                f.write(c)\n",
    "        print(\"Pretrained file has been downloaded successfully.\")\n"
   ],
   "id": "ea18148cb611d7fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This notebook evaluates accuracy from external source images as well as annotate the object",
   "id": "f43c7b962df099a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "img_data_dir = Path(\"data/images/\")\n",
    "imgs = [str(candidate)\n",
    "        for ext_pattern in (\n",
    "            '*.jpg',\n",
    "            '*.png',\n",
    "            '*.jpeg'\n",
    "        )\n",
    "        for candidate in img_data_dir.glob(ext_pattern)]\n",
    "\n",
    "if not imgs:\n",
    "    raise FileNotFoundError(\"Detection aborted due to no images with eligible extensions (JPG or PNG format) found.\")\n",
    "\n",
    "model = YOLO(model_file)\n",
    "\n",
    "results = model.predict(imgs, conf=0.7, imgsz=256)\n",
    "\n",
    "out_dir = Path(\"data/cnt_result/\")\n",
    "\n",
    "for idx, r in enumerate(results):\n",
    "    origin_name = Path(imgs[idx]).stem\n",
    "    export_path = out_dir / f\"{origin_name}_predict.jpg\"\n",
    "    cv2.imwrite(str(export_path.absolute()), r.plot())"
   ],
   "id": "ddb618181a3716f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Probability means': [\n",
    "        np.mean([float(r.probs.data[0]) for r in results[0:99]] # Car\n",
    "                + [float(r.probs.data[1]) for r in results[100:200]]), # Tank\n",
    "        np.mean([float(r.probs.data[1]) for r in results[0:99]] # Car (false detect as tank)\n",
    "                + [float(r.probs.data[0]) for r in results[100:200]]), # Tank (false detect as car)\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Probability mean of classification accuracy\")\n",
    "pd.DataFrame(data, index=[\"True\", \"False\"])"
   ],
   "id": "4dcaf716bb45670d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "conf_matrix = {\n",
    "    \"car\": {\n",
    "        \"car\": sum(r.probs.top1 == 0 for r in results[0:99]),\n",
    "        \"tank\": sum(r.probs.top1 == 1 for r in results[0:99]),\n",
    "    }, \"tank\": {\n",
    "        \"car\": sum(r.probs.top1 == 0 for r in results[100:200]),\n",
    "        \"tank\": sum(r.probs.top1 == 1 for r in results[100:200]),\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "pd.DataFrame(conf_matrix, index=[\"car\", \"tank\"])"
   ],
   "id": "7120d8bff7a8ec41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare true labels and prediction scores\n",
    "true_labels = []\n",
    "pred_scores = []  # Scores for the positive class (tank)\n",
    "\n",
    "# Assuming first 100 images are cars (class 0) and next 100 are tanks (class 1)\n",
    "for idx, r in enumerate(results):\n",
    "    # Get true label based on your dataset organization\n",
    "    if idx < 100:  # First 100 are cars\n",
    "        true_labels.append(0)  # Car = class 0\n",
    "    else:  # Next 100 are tanks\n",
    "        true_labels.append(1)  # Tank = class 1\n",
    "    \n",
    "    # Get probability for car class (class 0)\n",
    "    # r.probs.data[0] = car probability, r.probs.data[1] = tank probability\n",
    "    #print(float(r.probs.data[0]))\n",
    "    car_prob = float(r.probs.data[0])  # Probability for car class\n",
    "    pred_scores.append(car_prob)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "pred_scores = np.array(pred_scores)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, pred_scores, pos_label=0)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "         label='Random (AUC = 0.500)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print AUC value\n",
    "print(f\"AUC Score: {roc_auc:.3f}\")\n",
    "\n",
    "# Optional: Display some thresholds\n",
    "print(\"\\nSample thresholds:\")\n",
    "pd.DataFrame({\n",
    "    \"Threshold\": [thresholds[i] for i in range(0, len(thresholds), max(1, len(thresholds)//10))],\n",
    "    \"FPR\": [fpr[i] for i in range(0, len(thresholds), max(1, len(thresholds)//10))],\n",
    "    \"TPR\": [tpr[i] for i in range(0, len(thresholds), max(1, len(thresholds)//10))],\n",
    "})"
   ],
   "id": "3c7e0c5ae696f6fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
